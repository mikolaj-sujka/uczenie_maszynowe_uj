{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe: Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inżynieria cech\n",
    "Inżynieria cech to proces przekształcania danych w celu poprawy wydajności modeli uczenia maszynowego. Obejmuje to zarówno redukcję wymiarowości (np. metodą PCA), jak i selekcję cech, aby wybrać najbardziej informacyjne cechy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selekcja cech (różne algorytmy).\n",
    "Selekcja cech polega na wyborze podzbioru cech, które są najbardziej istotne dla danego problemu predykcyjnego. Można to zrobić na różne sposoby, np. na podstawie znaczenia cech określonego przez model lub poprzez univariate selection, gdzie każda cecha jest oceniana indywidualnie.\n",
    "- Celem jest zredukowanie liczby cech do tych, które są najbardziej informatywne i istotne dla modelu, co może prowadzić do poprawy jego wydajności, uproszczenia modelu i zmniejszenia ryzyka przeuczenia (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (bez selekcji cech): 0.9778\n",
      "Raport klasyfikacji (bez selekcji cech):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      1.00      0.99        47\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       1.00      1.00      1.00        60\n",
      "           5       0.97      0.95      0.96        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       0.95      0.95      0.95        43\n",
      "           9       0.97      0.97      0.97        59\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "Dokładność na zbiorze testowym (znaczenie cech): 0.9741\n",
      "Raport klasyfikacji (znaczenie cech):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.96      0.98      0.97        54\n",
      "           4       0.97      1.00      0.98        60\n",
      "           5       0.97      0.98      0.98        66\n",
      "           6       1.00      0.98      0.99        53\n",
      "           7       0.98      0.98      0.98        55\n",
      "           8       0.91      0.91      0.91        43\n",
      "           9       0.98      0.93      0.96        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n",
      "Dokładność na zbiorze testowym (SelectKBest): 0.9519\n",
      "Raport klasyfikacji (SelectKBest):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.98      0.90      0.94        50\n",
      "           2       0.88      0.98      0.93        47\n",
      "           3       0.98      0.93      0.95        54\n",
      "           4       0.97      0.98      0.98        60\n",
      "           5       0.97      0.95      0.96        66\n",
      "           6       0.96      0.98      0.97        53\n",
      "           7       0.92      0.98      0.95        55\n",
      "           8       0.86      0.86      0.86        43\n",
      "           9       0.98      0.93      0.96        59\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.95       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n",
      "Dokładność na zbiorze testowym (RFE): 0.9611\n",
      "Raport klasyfikacji (RFE):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       0.92      0.94      0.93        50\n",
      "           2       0.96      0.98      0.97        47\n",
      "           3       0.95      0.98      0.96        54\n",
      "           4       0.97      0.95      0.96        60\n",
      "           5       0.98      0.95      0.97        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       0.84      0.88      0.86        43\n",
      "           9       1.00      0.95      0.97        59\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.96      0.96      0.96       540\n",
      "\n",
      "Dokładność walidacji krzyżowej (RandomForest): 0.9772\n",
      "Dokładność walidacji krzyżowej (RandomForest z znaczeniem cech): 0.9555\n",
      "Dokładność walidacji krzyżowej (RandomForest z SelectKBest): 0.9555\n",
      "Dokładność walidacji krzyżowej (RandomForest z RFE): 0.9577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Załadowanie danych\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Usunięcie stałych cech\n",
    "X = X[:, X.var(axis=0) > 0]\n",
    "\n",
    "# Podział danych na zestawy treningowe i testowe\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Trenowanie modelu SVC bez selekcji cech\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym (bez selekcji cech): {accuracy:.4f}\")\n",
    "print(\"Raport klasyfikacji (bez selekcji cech):\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Selekcja cech na podstawie znaczenia cech\n",
    "selector = SelectFromModel(rf, prefit=True)\n",
    "X_train_rf = selector.transform(X_train)\n",
    "X_test_rf = selector.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu z selekcją cech (znaczenie cech)\n",
    "model.fit(X_train_rf, y_train)\n",
    "y_pred_rf = model.predict(X_test_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Dokładność na zbiorze testowym (znaczenie cech): {accuracy_rf:.4f}\")\n",
    "print(\"Raport klasyfikacji (znaczenie cech):\\n\", classification_report(y_test, y_pred_rf, zero_division=1))\n",
    "\n",
    "# Selekcja cech za pomocą SelectKBest (ANOVA)\n",
    "selector = SelectKBest(score_func=f_classif, k=20)\n",
    "X_train_best = selector.fit_transform(X_train, y_train)\n",
    "X_test_best = selector.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu po selekcji cech (SelectKBest)\n",
    "model.fit(X_train_best, y_train)\n",
    "y_pred_best = model.predict(X_test_best)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Dokładność na zbiorze testowym (SelectKBest): {accuracy_best:.4f}\")\n",
    "print(\"Raport klasyfikacji (SelectKBest):\\n\", classification_report(y_test, y_pred_best, zero_division=1))\n",
    "\n",
    "# Selekcja cech za pomocą RFE\n",
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "rfe = RFE(estimator=log_reg, n_features_to_select=20)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu po selekcji cech (RFE)\n",
    "model.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = model.predict(X_test_rfe)\n",
    "accuracy_rfe = accuracy_score(y_test, y_pred_rfe)\n",
    "print(f\"Dokładność na zbiorze testowym (RFE): {accuracy_rfe:.4f}\")\n",
    "print(\"Raport klasyfikacji (RFE):\\n\", classification_report(y_test, y_pred_rfe, zero_division=1))\n",
    "\n",
    "# Walidacja krzyżowa z RandomForestClassifier na oryginalnych danych\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=42), X, y, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest): {np.mean(cv_scores):.4f}\")\n",
    "\n",
    "# Walidacja krzyżowa z selekcją cech na podstawie znaczenia cech\n",
    "X_rf = selector.transform(X)\n",
    "cv_scores_rf = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=42), X_rf, y, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest z znaczeniem cech): {np.mean(cv_scores_rf):.4f}\")\n",
    "\n",
    "# Walidacja krzyżowa z SelectKBest\n",
    "X_best = selector.transform(X)\n",
    "cv_scores_best = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=42), X_best, y, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest z SelectKBest): {np.mean(cv_scores_best):.4f}\")\n",
    "\n",
    "# Walidacja krzyżowa z RFE\n",
    "X_rfe = rfe.transform(X)\n",
    "cv_scores_rfe = cross_val_score(RandomForestClassifier(n_estimators=100, random_state=42), X_rfe, y, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest z RFE): {np.mean(cv_scores_rfe):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redukcja wymiarowości: Metoda PCA\n",
    "Principal Component Analysis (PCA) to statystyczna metoda analizy danych, która przekształca dane o wysokiej wymiarowości na dane o mniejszej liczbie wymiarów. Celem PCA jest zredukowanie liczby wymiarów przy jednoczesnym zachowaniu jak największej ilości informacji zawartej w oryginalnych danych.\n",
    "- PCA może prowadzić do mniejszej dokładności modelu w porównaniu do modelu trenowanego bez redukcji wymiarowości. Dzieje się tak dlatego, że PCA zmniejsza liczbę cech, co może skutkować utratą istotnych informacji zawartych w danych. W niektórych przypadkach, szczególnie jeśli liczba wybranych komponentów jest zbyt mała, model może nie być w stanie uchwycić wszystkich istotnych wzorców w danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (bez redukcji): 0.9694\n",
      "Raport klasyfikacji (bez redukcji):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.96      0.95        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.97      0.93      0.95        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "\n",
      "Dokładność na zbiorze testowym (PCA): 0.5583\n",
      "Raport klasyfikacji (PCA):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.79      0.68        33\n",
      "           1       0.31      0.64      0.41        28\n",
      "           2       0.72      0.64      0.68        33\n",
      "           3       0.37      0.44      0.40        34\n",
      "           4       0.93      0.89      0.91        46\n",
      "           5       0.32      0.13      0.18        47\n",
      "           6       0.91      0.86      0.88        35\n",
      "           7       0.74      0.68      0.71        34\n",
      "           8       0.26      0.23      0.25        30\n",
      "           9       0.41      0.35      0.38        40\n",
      "\n",
      "    accuracy                           0.56       360\n",
      "   macro avg       0.56      0.56      0.55       360\n",
      "weighted avg       0.57      0.56      0.55       360\n",
      "\n",
      "Dokładność walidacji krzyżowej (RandomForest z PCA): 0.5720\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Wczytywanie danych\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu bez redukcji wymiarowości\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=model, param_grid=param_grid_rf, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym (bez redukcji): {accuracy:.4f}\")\n",
    "print(\"Raport klasyfikacji (bez redukcji):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Redukcja wymiarowości za pomocą PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu po redukcji wymiarowości za pomocą PCA\n",
    "grid_search_rf.fit(X_train_pca, y_train)\n",
    "best_rf_pca = grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = best_rf_pca.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"\\nDokładność na zbiorze testowym (PCA): {accuracy_pca:.4f}\")\n",
    "print(\"Raport klasyfikacji (PCA):\\n\", classification_report(y_test, y_pred_pca))\n",
    "\n",
    "# Walidacja krzyżowa z PCA i RandomForestClassifier\n",
    "cv_scores_pca = cross_val_score(best_rf_pca, X_train_pca, y_train, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest z PCA): {np.mean(cv_scores_pca):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ekstrakcja cech: transformacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (PolynomialFeatures): 0.9722\n",
      "Raport klasyfikacji (PolynomialFeatures):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.98      0.96        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.97      0.93      0.95        30\n",
      "           9       0.97      0.95      0.96        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Dokładność walidacji krzyżowej (RandomForest z PolynomialFeatures): 0.9694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Wczytywanie danych\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Ekstrakcja cech za pomocą transformacji (PolynomialFeatures)\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu z ekstrakcją cech (PolynomialFeatures)\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=model, param_grid=param_grid_rf, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train_poly, y_train)\n",
    "best_rf_poly = grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf_poly.fit(X_train_poly, y_train)\n",
    "y_pred_poly = best_rf_poly.predict(X_test_poly)\n",
    "accuracy_poly = accuracy_score(y_test, y_pred_poly)\n",
    "print(f\"Dokładność na zbiorze testowym (PolynomialFeatures): {accuracy_poly:.4f}\")\n",
    "print(\"Raport klasyfikacji (PolynomialFeatures):\\n\", classification_report(y_test, y_pred_poly))\n",
    "\n",
    "# Walidacja krzyżowa z ekstrakcją cech (PolynomialFeatures)\n",
    "cv_scores_poly = cross_val_score(best_rf_poly, X_train_poly, y_train, cv=cv)\n",
    "print(f\"Dokładność walidacji krzyżowej (RandomForest z PolynomialFeatures): {np.mean(cv_scores_poly):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ważność cech (w wytrenowanym modelu)\n",
    "(feature importance) odnosi się do metryki, która mierzy, jak bardzo dana cecha (zmienna) przyczynia się do predykcji modelu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (bez redukcji): 0.9694\n",
      "Raport klasyfikacji (bez redukcji):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.93      1.00      0.97        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.96      0.95        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.97      0.93      0.95        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "Ważność cech:\n",
      "1. Cecha 21: 0.0500\n",
      "2. Cecha 43: 0.0443\n",
      "3. Cecha 36: 0.0404\n",
      "4. Cecha 26: 0.0390\n",
      "5. Cecha 42: 0.0358\n",
      "6. Cecha 28: 0.0325\n",
      "7. Cecha 30: 0.0306\n",
      "8. Cecha 20: 0.0298\n",
      "9. Cecha 61: 0.0290\n",
      "10. Cecha 33: 0.0288\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "\n",
    "# Wczytywanie danych\n",
    "data = load_digits()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu bez redukcji wymiarowości\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_rf = GridSearchCV(estimator=model, param_grid=param_grid_rf, cv=cv, n_jobs=-1, scoring='accuracy')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym (bez redukcji): {accuracy:.4f}\")\n",
    "print(\"Raport klasyfikacji (bez redukcji):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Ważność cech\n",
    "importances = best_rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Ważność cech:\")\n",
    "for i in range(10):\n",
    "    print(f\"{i + 1}. Cecha {indices[i]}: {importances[indices[i]]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
