{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uczenie maszynowe: Lab4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inżynieria cech\n",
    "Inżynieria cech to proces przekształcania danych w celu poprawy wydajności modeli uczenia maszynowego. Obejmuje to zarówno redukcję wymiarowości (np. metodą PCA), jak i selekcję cech, aby wybrać najbardziej informacyjne cechy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selekcja cech (różne algorytmy).\n",
    "Selekcja cech polega na wyborze podzbioru cech, które są najbardziej istotne dla danego problemu predykcyjnego. Można to zrobić na różne sposoby, np. na podstawie znaczenia cech określonego przez model lub poprzez univariate selection, gdzie każda cecha jest oceniana indywidualnie.\n",
    "- Celem jest zredukowanie liczby cech do tych, które są najbardziej informatywne i istotne dla modelu, co może prowadzić do poprawy jego wydajności, uproszczenia modelu i zmniejszenia ryzyka przeuczenia (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (bez selekcji): 0.9778\n",
      "Raport klasyfikacji (bez selekcji):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      1.00      0.99        47\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       1.00      1.00      1.00        60\n",
      "           5       0.97      0.95      0.96        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       0.95      0.95      0.95        43\n",
      "           9       0.97      0.97      0.97        59\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "Dokładność na zbiorze testowym (znaczenie cech): 0.9741\n",
      "Raport klasyfikacji (znaczenie cech):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.96      0.96      0.96        50\n",
      "           2       1.00      1.00      1.00        47\n",
      "           3       0.96      0.98      0.97        54\n",
      "           4       0.97      1.00      0.98        60\n",
      "           5       0.97      0.98      0.98        66\n",
      "           6       1.00      0.98      0.99        53\n",
      "           7       0.98      0.98      0.98        55\n",
      "           8       0.91      0.91      0.91        43\n",
      "           9       0.98      0.93      0.96        59\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n",
      "Dokładność na zbiorze testowym (Univariate Selection): 0.3611\n",
      "Raport klasyfikacji (Univariate Selection):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.51      0.46        53\n",
      "           1       0.00      0.00      0.00        50\n",
      "           2       0.26      0.77      0.39        47\n",
      "           3       1.00      0.00      0.00        54\n",
      "           4       0.59      0.68      0.64        60\n",
      "           5       0.56      0.33      0.42        66\n",
      "           6       0.31      0.28      0.29        53\n",
      "           7       0.45      0.24      0.31        55\n",
      "           8       0.09      0.07      0.08        43\n",
      "           9       0.34      0.64      0.44        59\n",
      "\n",
      "    accuracy                           0.36       540\n",
      "   macro avg       0.40      0.35      0.30       540\n",
      "weighted avg       0.42      0.36      0.32       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "# Dane\n",
    "data = load_digits()\n",
    "\n",
    "X = data.data \n",
    "y = data.target \n",
    "\n",
    "# Usunięcie stałych cech\n",
    "X = X[:, X.var(axis=0) > 0]\n",
    "\n",
    "# Trenowanie modelu\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standaryzacja danych\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Tworzenie modelu Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Trening modelu bez selekcji cech\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym (bez selekcji): {accuracy:.4f}\")\n",
    "print(\"Raport klasyfikacji (bez selekcji):\\n\", classification_report(y_test, y_pred, zero_division=1))\n",
    "\n",
    "# Selekcja cech na podstawie znaczenia cech\n",
    "selector = SelectFromModel(rf, prefit=True) # wybiera cechy, które mają znaczenie # prefit = True, ponieważ model jest już wytrenowany\n",
    "X_train_rf = selector.transform(X_train)\n",
    "X_test_rf = selector.transform(X_test)\n",
    "\n",
    "# Trening modelu z selekcją cech (znaczenie cech)\n",
    "model.fit(X_train_rf, y_train)\n",
    "y_pred_rf = model.predict(X_test_rf)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Dokładność na zbiorze testowym (znaczenie cech): {accuracy_rf:.4f}\")\n",
    "print(\"Raport klasyfikacji (znaczenie cech):\\n\", classification_report(y_test, y_pred_rf, zero_division=1))\n",
    "\n",
    "# Wybieranie najlepszych cech za pomocą testu ANOVA\n",
    "# k - liczba cech do wybrania\n",
    "# score_func - funkcja oceny cech\n",
    "selector = SelectKBest(score_func=f_classif, k=2) #  wybiera k cech, które mają najwyższe wyniki dla wybranego testu statystycznego, \n",
    "# mierząc ich zależność z docelową zmienną\n",
    "X_train_best = selector.fit_transform(X_train, y_train)\n",
    "X_test_best = selector.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu po selekcji cech\n",
    "model.fit(X_train_best, y_train)\n",
    "y_pred_best = model.predict(X_test_best)\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(f\"Dokładność na zbiorze testowym (Univariate Selection): {accuracy_best:.4f}\")\n",
    "print(\"Raport klasyfikacji (Univariate Selection):\\n\", classification_report(y_test, y_pred_best, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redukcja wymiarowości: Metoda PCA\n",
    "Principal Component Analysis (PCA) to statystyczna metoda analizy danych, która przekształca dane o wysokiej wymiarowości na dane o mniejszej liczbie wymiarów. Celem PCA jest zredukowanie liczby wymiarów przy jednoczesnym zachowaniu jak największej ilości informacji zawartej w oryginalnych danych.\n",
    "- PCA może prowadzić do mniejszej dokładności modelu w porównaniu do modelu trenowanego bez redukcji wymiarowości. Dzieje się tak dlatego, że PCA zmniejsza liczbę cech, co może skutkować utratą istotnych informacji zawartych w danych. W niektórych przypadkach, szczególnie jeśli liczba wybranych komponentów jest zbyt mała, model może nie być w stanie uchwycić wszystkich istotnych wzorców w danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność na zbiorze testowym (bez redukcji): 0.9722\n",
      "Raport klasyfikacji (bez redukcji):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        33\n",
      "           1       0.97      1.00      0.98        28\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      0.94      0.97        34\n",
      "           4       0.98      1.00      0.99        46\n",
      "           5       0.94      0.96      0.95        47\n",
      "           6       0.97      0.97      0.97        35\n",
      "           7       0.97      0.97      0.97        34\n",
      "           8       0.97      0.97      0.97        30\n",
      "           9       0.95      0.95      0.95        40\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "\n",
      "Dokładność na zbiorze testowym (PCA): 0.5389\n",
      "Raport klasyfikacji (PCA):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.70      0.65        33\n",
      "           1       0.30      0.43      0.35        28\n",
      "           2       0.59      0.61      0.60        33\n",
      "           3       0.39      0.38      0.39        34\n",
      "           4       0.89      0.89      0.89        46\n",
      "           5       0.30      0.19      0.23        47\n",
      "           6       0.89      0.89      0.89        35\n",
      "           7       0.71      0.71      0.71        34\n",
      "           8       0.26      0.33      0.29        30\n",
      "           9       0.35      0.28      0.31        40\n",
      "\n",
      "    accuracy                           0.54       360\n",
      "   macro avg       0.53      0.54      0.53       360\n",
      "weighted avg       0.54      0.54      0.53       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wczytywanie danych\n",
    "data = load_digits()\n",
    "\n",
    "X = data.data \n",
    "y = data.target \n",
    "\n",
    "# Podział danych na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standaryzacja danych -> każda zmienna ma średnią 0 i wariancję 1 aby zmienne występujące w zbiorze danych były tej samej skali\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Trenowanie modelu bez redukcji wymiarowości\n",
    "# 100 drzew decyzyjnych\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Dokładność na zbiorze testowym (bez redukcji): {accuracy:.4f}\")\n",
    "print(\"Raport klasyfikacji (bez redukcji):\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Redukcja wymiarowości za pomocą PCA\n",
    "pca = PCA(n_components=2) # redukuje do 2 składowych głównych\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model.predict(X_test_pca)\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"\\nDokładność na zbiorze testowym (PCA): {accuracy_pca:.4f}\")\n",
    "print(\"Raport klasyfikacji (PCA):\\n\", classification_report(y_test, y_pred_pca))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
