{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konkretne dane -> podział na testowe i treningowe -> trenowanie modelu -> predykcja na danych testowych -> ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature1  feature2  label\n",
      "0          1         5      0\n",
      "1          2         4      1\n",
      "2          3         3      0\n",
      "3          4         2      1\n",
      "4          9         1      0\n",
      "5          2         3      1\n",
      "6          1         4      0\n",
      "7          3         1      1\n",
      "8          5         8      0\n",
      "9          5         9      1\n",
      "10        12        10      0 \n",
      "\n",
      "X_test =  (3, 2)\n",
      "Y_test =  (3,)\n",
      "X_train =  (8, 2)\n",
      "Y_train =  (8,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'feature1': [1, 2, 3, 4, 9, 2, 1, 3, 5, 5, 12],\n",
    "    'feature2': [5, 4, 3, 2, 1, 3, 4, 1, 8, 9, 10],\n",
    "    'label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "})\n",
    "\n",
    "print (df, \"\\n\")\n",
    "\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # test_size -> 80% training and 20% test\n",
    "print (\"X_test = \", X_test.shape)\n",
    "print (\"Y_test = \", y_test.shape,)\n",
    "print (\"X_train = \", X_train.shape)\n",
    "print (\"Y_train = \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (6 w TS, 2 w VS)\n",
      "[1 3 4 5 6 7]\n",
      "Fold 1 (6 w TS, 2 w VS)\n",
      "[0 2 4 5 6 7]\n",
      "Fold 2 (6 w TS, 2 w VS)\n",
      "[0 1 2 3 6 7]\n",
      "Fold 3 (6 w TS, 2 w VS)\n",
      "[0 1 2 3 4 5]\n",
      "\n",
      "Cross-Validation Scores: \n",
      " [0.5 0.5 0.5 1. ]\n",
      "Mean Cross-Validation Score:  0.625\n",
      "\n",
      "Best Hyperparameters: \n",
      " {'var_smoothing': 1e-09}\n",
      "\n",
      "Test Set Predictions: \n",
      " [0 0 1]\n",
      "\n",
      "Class Priors: \n",
      " [0.5 0.5]\n",
      "\n",
      "Means: \n",
      " [[4.75 6.75]\n",
      " [2.75 2.5 ]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         2\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.25      0.25      0.25         3\n",
      "weighted avg       0.33      0.33      0.33         3\n",
      "\n",
      "\n",
      "Cross-Validation Scores: \n",
      " [0.66666667 0.66666667 0.66666667 0.5       ]\n",
      "Mean Cross-Validation Score:  0.625\n"
     ]
    }
   ],
   "source": [
    "# Walidacja krzyżowa k - fold\n",
    "# Dzielimy na k równych podzbiorów (w których każdy z podzbiorów raz występuje jako zbiór uczący, a pozostała, połączona \n",
    "# część zbioru jest wykorzystywana jako zbiór testowy)\n",
    "\n",
    "k = 4\n",
    "cv = StratifiedKFold(n_splits=k)\n",
    "model = GaussianNB()\n",
    "\n",
    "cross_val_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "fold = 0\n",
    "for fold, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(\"Fold {} ({} w TS, {} w VS)\".format(fold, len(train), len(test)))\n",
    "    print(train)\n",
    "\n",
    "print(\"\\nCross-Validation Scores: \\n\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Score: \", cross_val_scores.mean())\n",
    "\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"\\nBest Hyperparameters: \\n\", grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nTest Set Predictions: \\n\", y_pred)\n",
    "\n",
    "# Display learned parameters (specific to Naive Bayes)\n",
    "print(\"\\nClass Priors: \\n\", best_model.class_prior_)\n",
    "print(\"\\nMeans: \\n\", best_model.theta_)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Cross-Validation Scores with the best model\n",
    "cross_val_scores = cross_val_score(best_model, X, y, cv=cv)\n",
    "print(\"\\nCross-Validation Scores: \\n\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Score: \", cross_val_scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
