{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analiza modelu klasyfikacyjnego"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konkretne dane -> podział na testowe i treningowe -> trenowanie modelu -> predykcja na danych testowych -> ocena modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "\n",
      "X_test =  (30, 4)\n",
      "Y_test =  (30,)\n",
      "X_train =  (120, 4)\n",
      "Y_train =  (120,)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "df = pd.read_csv(url, header=None)\n",
    "\n",
    "print(df)\n",
    "\n",
    "data = df.values\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1] # etykiety\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) # test_size -> 80% training and 20% test\n",
    "print (\"\\nX_test = \", X_test.shape)\n",
    "print (\"Y_test = \", y_test.shape,)\n",
    "print (\"X_train = \", X_train.shape)\n",
    "print (\"Y_train = \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 (108 w TS, 12 w VS)\n",
      "[  9  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 1 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8  10  11  12  22  23  24  25  26  27\n",
      "  28  29  30  32  33  34  35  36  37  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 2 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  30  31  32  33  34  35  36  37  38  40  41  44  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 3 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  31  35  36  38  39  41\n",
      "  42  43  44  45  47  49  51  53  54  55  56  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 4 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  37\n",
      "  38  39  40  42  43  45  46  47  48  49  50  51  52  57  58  59  60  62\n",
      "  64  65  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 5 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  48  50  52  53  54  55  56\n",
      "  57  58  61  63  65  66  67  68  73  74  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 6 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  66  67  69  70  71  72  75\n",
      "  83  84  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 7 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  85  93  94  95  96 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 8 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  97  98  99 106 107 110 111 112 113 114 115 116 117 118 119]\n",
      "Fold 9 (108 w TS, 12 w VS)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 108 109]\n"
     ]
    }
   ],
   "source": [
    "# Walidacja krzyżowa k - fold\n",
    "# Dzielimy na k równych podzbiorów (w których każdy z podzbiorów raz występuje jako zbiór uczący, a pozostała, połączona \n",
    "# część zbioru jest wykorzystywana jako zbiór testowy)\n",
    "\n",
    "k = 10\n",
    "cv = StratifiedKFold(n_splits=k)\n",
    "\n",
    "fold = 0\n",
    "for fold, (train, test) in enumerate(cv.split(X_train, y_train)):\n",
    "    print(\"Fold {} ({} w TS, {} w VS)\".format(fold, len(train), len(test)))\n",
    "    print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Naive Bayes\n",
    "model = GaussianNB()\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - kNN\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - Drzewo decyzyjne\n",
    "model = DecisionTreeClassifier()\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Regresja logistyczna\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - LDA\n",
    "model = LinearDiscriminantAnalysis()\n",
    "param_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': [None, 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 - MLP\n",
    "model = MLPClassifier(max_iter=10000)\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 - SVM\n",
    "model = SVC()\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 - Bagging\n",
    "model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100, random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_samples': [0.5, 0.7, 1.0],\n",
    "    'max_features': [0.5, 0.7, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 - Boosting\n",
    "model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 - Lasy losowe\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wyniki walidacji krzyżowej: \n",
      " [0.91666667 1.         0.91666667 1.         1.         1.\n",
      " 1.         1.         0.91666667 0.91666667]\n",
      "Średni wynik walidacji krzyżowej:  0.9666666666666666\n",
      "\n",
      "Najlepsze hiperparametry: \n",
      " {'activation': 'tanh', 'hidden_layer_sizes': (50, 50), 'solver': 'sgd'}\n",
      "\n",
      "Predykcje na zbiorze testowym \n",
      " ['Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Walidacja krzyżowa - technika trenowania i testowania modelu na różnych podzbiorach danych\n",
    "print(\"\\nWyniki walidacji krzyżowej: \\n\", cross_val_scores)\n",
    "print(\"Średni wynik walidacji krzyżowej: \", cross_val_scores.mean())\n",
    "\n",
    "# Grid Search -> wyszukanie najlepszych hiperparametrów\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nNajlepsze hiperparametry: \\n\", grid_search.best_params_)\n",
    "\n",
    "# Trenowanie modelu z najlepszymi hiperparametrami\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predykcje i ocena na zbiorze testowym\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nPredykcje na zbiorze testowym \\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyświetlanie wyuczonych parametrów (specyficznych dla Naive Bayes)\n",
    "if hasattr(best_model, 'class_prior_'):\n",
    "    print(\"\\nWyuczone parametry: \\n\", best_model.class_prior_)\n",
    "    print(\"\\nŚrednia: \\n\", best_model.theta_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raport klasyfikacji: \n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00         6\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Wyniki walidacji krzyżowej: \n",
      " [1.         1.         1.         1.         0.86666667 1.\n",
      " 0.93333333 1.         1.         1.        ]\n",
      "Średni wynik walidacji krzyżowej:  0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# Raport klasyfikacji\n",
    "print(\"\\nRaport klasyfikacji: \\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Wykonanie walidacji krzyżowej na całym zbiorze danych (z najlepszym modelem)\n",
    "cross_val_scores = cross_val_score(best_model, X, y, cv=cv)\n",
    "print(\"\\nWyniki walidacji krzyżowej: \\n\", cross_val_scores)\n",
    "print(\"Średni wynik walidacji krzyżowej: \", cross_val_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczenie nienadzorowane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inżynieria cech"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
